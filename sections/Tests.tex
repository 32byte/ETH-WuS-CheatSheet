\section{Tests}
\begin{subbox}{Null- und Alternativhypothese}
	Die Nullhypothese \(H_0\) und die Alternativhypothese \(H_A\) sind zwei Teilmengen \(\Theta_0 \subseteq \Theta, \Theta_A \subseteq \Theta\) wobei \(\Theta_0 \cap \Theta_A = \varnothing\). 

	Falls keine explizite Alternativhypothese spezifiziert ist, so hat man $\Theta_A = \Theta \setminus \Theta_0$. 

	Eine Hypothese heisst \textit{einfach}, falls die Teilmenge aus einem einzelnen Wert besteht; sonst \textit{zusammengesetzt}.
\end{subbox}

\begin{mainbox}{Definition Test}
	Ein Test ist ein Tupel \((T,K)\), wobei \(T\) eine \(ZV\) der Form \(T=t(X_1, \ldots, X_n)\) und \(K \subseteq \R\) eine deterministische Teilmenge von \(\R\) ist. Wir nennen \(T\) die \textit{Teststatistik} und \(K\) den \textit{Verwerfungsbereich} oder kritischen Bereich.
\end{mainbox}

Wir wollen nun anhand der Daten \((X_1(\omega), \ldots, X_n(\omega))\) entscheiden, ob die Nullhypothese akzeptiert oder verworfen wird. Zuerst berechnen wir die Teststatistik \(T(\omega) = t(X_1(\omega), \ldots, X_n(\omega))\) und gehen dann wie folgt vor:
\begin{itemize}
	\item Die Hypothese \(H_0\) wird \textit{verworfen}, falls \(T(\omega) \in K\).
	\item Die Hypothese \(H_0\) wird \textit{akzeptiert}, falls \(T(\omega) \notin K\).
\end{itemize}
\begin{subbox}{Fehler 1. und 2. Art}
	Ein Fehler 1. Art ist, wenn \(H_0\) fälschlicherweise verworfen wird, obwohl sie richtig ist.
	\[\P_\theta(T \in K), \quad \theta \in \Theta_0\]
	\noindent Ein Fehler 2. Art ist, wenn \(H_0\) fälschlicherweise akzeptiert wird, obwohl sie falsch ist.
	\[\P_\theta(T\notin K) = 1 - \P_\theta(T \in K), \quad \theta \in \Theta_A\]
\end{subbox}
\textbf{Bemerkung: } Da $T$ eine ZV und somit bezüglich dem Mass $\P_\theta: \F \to [0,1]$ messbar ist, gilt $\{T \in K\} \in \F$ und somit ist $\P_\theta(T \in K)$ wohldefiniert. 
\subsection{Signifikanzniveau und Macht}
Ein Test hat Signifikanzniveau \(a \in [0,1]\) falls
\[\forall \theta \in \Theta_0 \quad \P_\theta[T \in K] \le a\]
Es ist meist unser primäres Ziel, die Fehler 1. Art zu minimieren.

Das sekundäre Ziel ist, Fehler 2. Art zu vermeiden. Hierfür definieren wir die Macht eines Tests als Funktion:
\[\beta : \Theta_A \mapsto [0,1], \quad \theta \mapsto \P_\theta[T \in K]\]
Zu beachten ist, dass eine kleine Wahrscheinlichkeit für einen Fehler 2. Art einem \textit{grossen} \(\beta\) entspricht.

\subsection{Konstruktion von Tests}
Wir nehmen an, dass \(X_1, \ldots, X_n\) diskret oder gemeinsam stetig unter \(\P_{\theta_0}\) und \(\P_{\theta_A}\) sind, wobei \(\theta_0 \ne \theta_A\) einfach sind.

\noindent Der Likelihood-Quotient ist somit wohldefiniert:
\[R(x_1, \ldots, x_n) = \frac{L(x_1,\ldots, x_n;\theta_A)}{L(x_1, \ldots, x_n;\theta_0)}\]
(Falls \(L(x_1, \ldots, x_n; \theta_0) = 0\) setzen wir \(R(x_1, \ldots, x_n) = +\infty\).) Wenn \(R \gg 1\), so gilt \(H_A > H_0\) und analog \(R \ll 1 \implies H_A < H_0\).

\begin{subbox}{Likelihood-Quotient-Test}
	Der Likelihood-Quotient-Test (LQ-Test) mit Parameter \(c \ge 0\) ist definiert durch:
	\[T = R(x_1, \ldots, x_n) \quad \text{und} \quad K = (c, \infty]\]
\end{subbox}
Der LQ-Test ist optimal, da jeder andere Test mit kleinerem Signifikanzniveau auch eine kleinere Macht hat (Neyman-Pearson-Lemma).

\subsection{p-Wert}
Sei \(T = t(X_1, \ldots, X_n)\) eine Teststatistik und \((T,K_t)_{t\ge 0}\) eine Familie von Tests.

\begin{subbox}{Geordnete Teststatistik}
	Eine Familie von Tests heisst geordnet bzgl. \(T\) falls \(K_t \subset \R\) und \(s \le t \implies K_t \subset K_S\). Beispiele:
	\begin{itemize}
		\item \(K_t = (t, \infty)\) (rechtsseitiger Test)
		\item \(K_t = (-\infty, -t)\) (linksseitiger Test)
		\item \(K_t = (-\infty, -t) \cup (t, \infty)\) (beidseitiger Test)
	\end{itemize}
\end{subbox}

\begin{mainbox}{Definition p-Wert}
	Sei \(H_0: \theta = \theta_0\) eine einfache Nullhypothese. Sei \((T, K_t)_{t\ge 0}\) eine geordnete Familie von Tests. Der \(p\)-Wert ist definiert als ZV \(G(t)\), wobei
	\[G: \R_+ \mapsto [0,1], \quad G(t) = \P_{\theta_0}[T \in K_t]\]
\end{mainbox}
Der \(p\)-Wert hat folgende Eigenschaften:
\begin{enumerate}
	\item Sei \(T\) stetig und \(K_t = (t, \infty)\). Dann ist der \(p\)-Wert unter \(\P_{\theta_0}\) auf \([0,1]\) gleichverteilt.
	\item Für einen \(p\)-Wert \(\gamma\) gilt, dass alle Tests mit Signifikanzniveau \(\alpha > \gamma\) die Nullhypothese verwerfen.
\end{enumerate}

Insgesamt gilt also:
\[\text{kleiner } p\text{-Wert} \implies H_0 \text{ wird wahrscheinlich verworfen} \]

