\section{Zufallsvariablen}
Sei ($\Omega, \A, \P$) ein diskreter Wahrscheinlichkeitsraum.
\begin{mainbox}{Zufallsvariable}
    Eine (reellwertige) \textbf{Zufallsvariable} auf $\Omega$ ist eine messbare Funktion $X: \Omega \to \R$.
    $$X: \Omega \to \R \textbf{ messbar} \iff \forall x \in \R: X^{-1}(\{x\}) \in \A$$
 
    Die Eigenschaft \textbf{messbar} ist bezüglich dem Wahrscheinlichkeitsmass $\P$ relevant (i.e. dann ist $\P(X = x) := \P(\{\omega \in \Omega \mid X(\omega) = x\})$ wohldefiniert).
\end{mainbox}
Diese Definition von \textbf{messbar} ist für diskrete $\Omega$ äquivalent zu derjenigen der Vorlesung, die die rechte Seite vom '$\iff$' für alle abgeschlossenen Teilmengen $B \subset \R$ fordert. 

Für die Messbarkeit von $X$ ist nur $X(\Omega) \subseteq \R$ entscheidend und jede Teilmenge $A \subseteq X(\Omega)$ ist abzählbar (da $\Omega$ abzählbar). Somit kann $X^{-1}(A)$ als abzählbare Vereinigung von $\bigcup_{x \in A} X^{-1}(\{x\})$ geschrieben werden. 
\\($\implies X^{-1}(A) \in \A$ per Def. $\sigma$-Algebra)
\subsection{Verteilungsfunktion}
Die \textbf{Verteilungsfunktion} ist die Abbildung $F_X : \R \to [0,1]$ definiert durch:
$$F_X(t) := \P(X \leq t), \forall t \in \R$$
\vfill\break
Die Funktion erfüllt folgende Eigenschaften:
\begin{enumerate}
    \item $F_X$ ist monoton wachsend 
    \item $F_X$ ist rechtsstetig, i.e. $\lim_{h \downarrow 0}F_X(x+h) = F_X(x)$
    \item $\lim_{x \to -\infty}F_X(x) = 0$ und $\lim_{x \to \infty}F_X(x) = 1$
    \item $\forall a,b \in \R, a < b: \P(a < X \leq b) = F_X(b) -F_X(a)$ 
\end{enumerate}

\textbf{Linksstetigkeit}

Die Verteilungsfunktion ist nicht immer linksstetig.
\\Sei $F_X(a-) := \lim_{h \downarrow 0}F_X(a-h)$ für $a \in \R$ beliebig.

Dann gilt:
$$\P(X = a) = F_X(a) - F_X(a-)$$

Intuitiv folgt daraus
\begin{itemize}
    \item Wenn $F_X$ in einem Punkt $a \in \R$ nicht stetig ist, dann ist die ''Sprunghöhe'' $F_X(a)-F_X(a-)$ gleich der Wahrscheinlichkeit $\P(X = a)$.
    \item Falls $F_X$ stetig in einem Punkt $a \in \R$, dann gilt $\P(X = a) = 0$. 
\end{itemize}

\begin{mainbox}{Unabhängigkeit von Zufallsvariablen}
    Seien $X_1, ...,X_n$ Zufallsvariablen auf einem Wahrscheinlichkeitsraum $(\Omega, \A, \P)$. Dann heissen $X_1, ...,X_n$ \textbf{unabhängig}, falls
    \begin{align*}
        &\forall x_1, ..., x_n \in \R:\\
        &\P(X_1 \leq x_1, ..., X_n \leq x_n) = \P(X_1 \leq x_1)\cdot ... \cdot \P(X_n \leq x_n).
    \end{align*} 
\end{mainbox}

\begin{subbox}{Unendlich viele Bernoulli-Experimente}
    TBD
\end{subbox}

\subsection{Diskrete Zufallsvariablen}
Sei $A \in \F$ ein Ereignis. \\
Wir sagen $A$ tritt \textbf{fast sicher (f.s.)} ein, falls $\P(A)= 1$.
\\ \\
Seien $X, Y: \Omega \to \R$ Zufallsvariablen: \\$X \leq Y$ f.s. $\iff$ $\P(X \leq Y)=1$


\begin{mainbox}{Diskrete Zufallsvariable}
    Eine Zufallsvariable $X: \Omega \to \R$ heisst \textbf{diskret}, falls eine endliche oder abzählbare Menge $W \subset \R$ existiert, sodass
    $$\P(X \in W) = 1$$
    Falls $\Omega$ endlich oder abzählbar ist, dann ist $X$ immer diskret.
\end{mainbox}
Die \textbf{Verteilungsfunktion} einer diskreten ZV $X$: $$F_X(x)= \P(X \leq x)= \sum_{y\in W}p(y)\cdot \mathds{1}_{y\leq x}$$
Die \textbf{Gewichtsfunktion} einer diskreten ZV $X$: $$\forall x \in X(\Omega): p(x)= \P(X=x) \text{ wobei} \sum_{x \in X(\Omega)}p(x)= 1$$

\subsection{Diskrete Verteilungen}
\textbf{Bernoulli-Verteilung} ($X \sim \text{Ber}(p)$): 

$X(\Omega)= \{0, 1\}$ und die Gewichtsfunktion ist definiert durch
$$p(1):= \P(X = 1) = p \text{ und } p(0):=\P(X = 0) = 1 - p.$$
\textbf{Binomialverteilung} ($X \sim \text{Bin}(n, p)$): 

Wiederholung von $n$ unabhängigen Bernoulli-Experimenten mit gleichem Parameter $p$. 
$$p(k):= \P(X = k) = \binom{n}{k} \cdot p^k \cdot (1-p)^{n-k} \quad \forall k \in \{0,1,\ldots, n\}$$
\textbf{Geometrische Verteilung} ($X \sim \text{Geo}(p)$): 

Warten auf den $1$-ten Erfolg. 
$$p(k):= \P(X = k) = (1-p)^{k-1}\cdot p \quad \forall k \in \N\setminus\{0\}$$
\textbf{Poisson-Verteilung} ($X \sim \text{Poisson}(\lambda)$): 

Grenzwert der Binomialverteilung für grosse $n$ und kleine $p$. 
$$p(k) := \P(X = k) = \frac{\lambda^k}{k!}\cdot e^{-\lambda} \quad \forall k \in \N_0, \lambda > 0$$
\begin{enumerate}
    \item Für $X_n \sim \text{Bin}(n, \frac{\lambda}{n})$ gilt $\lim_{n \to \infty}\P(X_n = k) = \P(Y = k)$ wobei $Y \sim \text{Poisson}(\lambda)$.
    \item Seien $X_1 \sim \text{Poisson}(\lambda_1)$ und $X_2 \sim \text{Poisson}(\lambda_2)$ unabhängig. Dann gilt $(X_1 + X_2) \sim \text{Poisson}(\lambda_1 +\lambda_2)$.
\end{enumerate}

\subsection{Stetige Zufallsvariablen}
\begin{mainbox}{Stetige Zufallsvariablen, Dichte}
    Eine Zufallsvariable $X: \Omega \to \R$ heisst \textbf{stetig}, wenn ihre Verteilungsfunktion $F_X$ wie folgt geschrieben werden kann
    $$F_X(a) = \int_{-\infty}^{a}f(x)\dx = \text{ für alle }a \in \R.$$
    wobei $f: \R \to \R^+$ eine nicht-negative Funktion ist. $f$ wird dann als \textbf{Dichte} von $X$ benannt.\\
    Wenn $f: (\R, \mathcal{B}) \to (\R, \mathcal{B})$ messbar ist, ist die Zufallsvariable $X$ \textbf{absolut stetig}.
\end{mainbox}
\textbf{Intuition:} $f(x)\dx$ ist die Wahrscheinlichkeit, dass $X \in [x, x + \dx]$.
\\ \\
\textbf{Von $F_X$ zu $f$:} 

Sei $X$ eine Zufallsvariable mit stetiger Verteilungsfunktion $F_X$ und $F_X$ stückweise $\mathcal{C}^1$, d.h. es gibt $x_0 = - \infty < \ldots < x_{n-1} < x_n = +\infty$, sodass $F_X$ auf jedem Intervall $(x_i, x_{i+1})$ Element von $\mathcal{C}^1$ ist. 

Dann ist $X$ eine stetige Zufallsvariable und die Dichte $f$ kann wie folgt konstruiert werden:
$$\forall x \in (x_i, x_{i+1}) \quad f(x) = F'_X(x).$$

\subsection{Stetige Verteilungen}
\textbf{Gleichverteilung} ($X \sim \mathcal{U}([a,b])$): 

Die Dichte ist auf dem Intervall $[a, b]$ gleich. 
$$f_{a,b}(x) = \begin{cases}
    0 & x \notin [a,b]\\
    \frac{1}{b-a} & x \in [a,b]
\end{cases}$$
\textbf{Exponentialverteilung} ($T \sim \text{Exp}(\lambda)$): 

Lebensdauer oder Wartezeit eines allg. Ereignisses (Stetiges Äquivalent zur Geometrischen Verteilung).
$$f_\lambda(x) = \begin{cases}
    \lambda e^{-\lambda x} & x \ge 0,\\
    0 & x < 0.
\end{cases}$$ 
\textbf{Normalverteilung} ($X \sim \mathcal{N}(m, \sigma^2)$): 

Häufig verwendete Verteilung. Undefiniert für $\sigma = 0$.
$$f_{m, \sigma}(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-m)^2}{2\sigma^2}}$$
\begin{enumerate}
    \item Seien $X_1, \ldots, X_n$ \textbf{unabhängige} normalverteilte ZV mit Parametern $(m_1,\sigma_1^2), \ldots, (m_n, \sigma_n^2)$, dann ist 
    $$Z = m_0 + \lambda_1 X_1 + \ldots + \lambda_n X_n$$
    eine normalverteilte ZV mit Parametern $m = m_0 + \lambda_1 m_1 + \ldots + \lambda_n m_n$ und $\sigma^2 = \lambda_1^2 \sigma_1^2 + \ldots + \lambda_n^2 \sigma_n^2$.
    \item Sei $Z \sim \mathcal{N}(0,1)$ eine \textbf{standardnormalverteilte} Zufallsvariable. Dann gilt für $X \sim \mathcal{N}(m, \sigma^2)$ 
    $$X = m + \sigma \cdot Z$$   
\end{enumerate}

\subsection{Erwartungswert}
\begin{mainbox}{Erwartungswert - Diskrete ZV}
    Sei $X: \Omega \to \R$ eine diskrete Zufallsvariable, $W_X := X(\Omega)$ und $\phi: \R \to \R$ eine Abbildung. Falls die Summe wohldefiniert ist, gilt: 
    $$\mathbb{E}(\phi(X)) := \sum_{x \in W_X} \phi(x) \cdot \P(X = x)$$
    Wenn $X: \Omega \to \N_0$, kann man auch den Erwartungswert als
    $$\mathbb{E}(X) = \sum_{n = 0}^{\infty}\P(X > n)$$
    schreiben.
\end{mainbox}
\begin{mainbox}{Erwartungswert - Stetige ZV}
    Sei $X: \Omega \to \R$ eine stetige Zufallsvariable mit Dichte $f$. Sei $\phi: \R \to \R$ eine Abbildung, sodass $\phi(X)$ eine Zufallsvariable ist. Dann gilt
    $$\mathbb{E}(\phi(X))= \int_{-\infty}^\infty \phi(x)f(x)\dx,$$
    solange das Integral wohldefiniert ist.
    \\Sei $X$ eine stetige ZV mit $X \geq 0$ f.s., dann gilt:
    $$\E(X)=\int_0^\infty \P(X > x)\dx$$ 
\end{mainbox}

\subsection{Rechnen mit Erwartungswerten}
\textbf{Linearität des Erwartungswertes}: 

Seien $X, Y: \Omega \to \R$ ZV mit $\lambda \in \R$, Falls die Erwartungswerte wohldefiniert sind, gilt:
$$\mathbb{E}(\lambda \cdot X + Y) = \lambda \cdot \mathbb{E}(X) + \mathbb{E}(Y)$$

Falls $X, Y$ \textbf{unabhängig}, dann gilt auch:
$$\mathbb{E}(X \cdot Y) = \mathbb{E}(X) \cdot \mathbb{E}(Y)$$

Eine generellere Form wäre folgende Äquivalenz:\\
$X_1, X_2, ...,X_n$ unabhängig
\\$\iff$
\\Für jede $\phi_1: \R \to \R, \ldots, \phi_n: \R \to \R$ stückweise stetig, beschränkt gilt
$$\E(\phi_1(X_1)\cdots\phi_n(X_n))=\E(\phi_1(X_1))\cdots\E(\phi_n(X_n))$$ 

\subsection{Ungleichungen}
\textbf{Monotonie}
\\Seien $X, Y$ ZV mit $X \leq Y$ f.s., dann gilt:
$$\E(X) \leq \E(Y)$$
\textbf{Markov Ungleichung}
\\Sei $X$ eine ZV und ferner $g: X(\Omega) \to [0, +\infty)$ eine wachsende Funktion. Für jedes $c \in \R$ mit $g(c) > 0$ gilt dann
$$\P(X \geq c) \leq \frac{\E(g(X))}{g(c)}$$
\\\textit{Einfache Version:}
\\Sei $X$ eine ZV mit $X\geq 0$ f.s., dann gilt für jedes $t > 0$:
$$\P(X \geq t) \leq \frac{\E(X)}{t}$$
\textbf{Chebyshev Ungleichung}
\\Sei $Y$ eine ZV mit endlicher Varianz. Für jedes $b > 0$ gilt dann
$$\P(|Y - \E(Y)| \geq b) \leq \frac{\text{Var}(Y)}{b^2}$$
\textbf{Jensen Ungleichung}
\\Sei $X$ eine ZV und $\phi: \R \to \R$ eine konvexe Funktion, dann gilt:
$$\phi(\E(X)) \leq \E(\phi(X))$$

\subsection{Varianz}
\begin{mainbox}{Varianz}
    Sei $X$ eine ZV, sodass $\E(X^2)<\infty$. Die \textbf{Varianz} von $X$ ist definiert durch
    $$\Var(X) = \sigma_X^2 = \E((X - m)^2) = \E(X^2)-\E(X)^2$$
    wobei $m = \E(X)$. Dabei wird $\sigma_X$ als \textbf{Standardabweichung} von $X$ bezeichnet und beschreibt den Erwartungswert für die Distanz von $X$ zu $\E(X)$.
\end{mainbox}

\begin{enumerate}
    \item Sei $X$ ein ZV, sodass $\E(X^2)<\infty$ und $\lambda \in \R$:
    $$\Var(a\cdot X + b) = a^2 \cdot \Var(X)$$
    \item Seien $X_1, ..., X_n$ paarweise unabhängig. Dann gilt
    $$\Var(X_1 + \ldots + X_n) = \Var(X_1)+\ldots +\Var(X_n)$$
\end{enumerate}

\begin{mainbox}{Kovarianz}
    Seien $X, Y$ ZV mit $\E(X^2)<\infty, \E(Y^2) < \infty$. Wir definieren die \textbf{Kovarianz} zwischen $X$ und $Y$ durch
    $$\text{Cov}(X,Y) := \E(XY) - \E(X)\E(Y)$$
\end{mainbox}
\begin{enumerate}
    \item $\text{Cov}(X,X) = \Var(X)$
    \item $X, Y$ unabhängig $\implies$ $\text{Cov}(X, Y) = 0$ (Die Umkehrung ist falsch!)
    \item $\Var(X+Y) = \Var(X) + \Var(Y) + 2\text{Cov}(X, Y)$
\end{enumerate}
\subsection{Bedingter Erwartungswert}
Sei $(\Omega, \A, \P)$ ein diskreter Wahrscheinlichkeitsraum und $X:\Omega \to \R$ eine Zufallsvariable. 

Für ein beliebiges $B \in A, \P(B) > 0$ definieren wir den \textbf{bedingten Erwartungswert} $X$ bedingt durch $B$ als
\begin{align*}
    \E(X \mid B) = \frac{\E(\mathds{1}_B X)}{\P(B)} &= \sum_{x \in X(\Omega)}x\P(X = x\mid B)\\ 
    &= \sum_{\omega \in \Omega}X(\omega)\P(\{\omega\}\mid B)
\end{align*}

\textbf{Bedingter Erwartungswert als Zufallsvariable}\\
Wir betrachten eine Partition $\mathcal{B} = (B_i)_{i \in I}$ von $\Omega$ ($B_i$ sind disjunkt und nichtleer, $I$ abzählbar). 

Dann definieren wir die \textbf{Zufallsvariable}
$$\E(X \mid \mathcal{B})(\omega) = \sum_{i \in I, \P(B_i > 0)} \E(X \mid B_i) \mathds{1}_{B_i}(\omega)$$ 
\begin{enumerate}
    \item \textbf{Intuition:} Die Information, die durch die Partition gegeben ist, ist dass eines der $B_i$ eintreten wird. Bei der Realisierung durch das Eintreten des Elementarereignisses $\omega$ wird $\E(X \mid \mathcal{B})$ zu dem $\E(X \mid B_i)$ realisiert, bei welchem $\omega \in B_i$.
    \item \textbf{Bemerkung:} Das $\mathcal{B}$ hat in der Vorlesung 2 verschiedene Bedeutungen. Es wird als Variable für sowohl die Borelsche $\sigma$-Algebra als auch die Partition von $\Omega$ verwendet.
\end{enumerate}
